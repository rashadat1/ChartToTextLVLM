{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /opt/anaconda3/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in /opt/anaconda3/lib/python3.11/site-packages (from ollama) (0.25.2)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.1.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.27)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.30)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.29->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /opt/anaconda3/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pytesseract) (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary modules\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import HuggingFaceHub\n",
    "import torch.nn.functional\n",
    "from PIL import Image\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pytesseract\n",
    "import ollama\n",
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration, AutoModelForCausalLM, AutoTokenizer\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use google deplot hungging face api to generate the underlying data table for the chart passed in\n",
    "def ExtractChartMetadata(image_file):\n",
    "  device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "  processor = Pix2StructProcessor.from_pretrained('google/deplot')\n",
    "  model = Pix2StructForConditionalGeneration.from_pretrained('google/deplot').to(device)\n",
    "\n",
    "  model.to(device)\n",
    "  image = Image.open(image_file)\n",
    "  inputs = processor(images = image, text = 'Generate underlying data table of the figure below:',return_tensors='pt').to(device)\n",
    "  inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "  predictions = model.generate(**inputs,max_new_tokens = 512)\n",
    "\n",
    "  output_text = processor.decode(predictions[0].to('cpu'),skip_special_tokens=True)\n",
    "  torch.mps.empty_cache()\n",
    "  return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseRawTextDF(raw_text):\n",
    "    # Replace <0x0A> with a newline character for easier processing\n",
    "    raw_text = raw_text.replace(\"<0x0A>\", \"\\n\")\n",
    "    # Split the text into lines\n",
    "    lines = raw_text.split(\"\\n\")\n",
    "    # Dynamically parse each line into a list of columns\n",
    "    data = [line.split(\" | \") for line in lines if line]  # Ensure no empty lines are processed\n",
    "\n",
    "    # Handle variable number of columns by checking the length of each row\n",
    "    max_cols = max(len(row) for row in data)\n",
    "    columns = data[0] if len(data[0]) == max_cols else [f\"Column {i+1}\" for i in range(max_cols)]\n",
    "\n",
    "    # Ensure all rows have the same number of columns, filling missing values with None\n",
    "    data_normalized = [row + [None] * (max_cols - len(row)) for row in data]\n",
    "\n",
    "    # Convert to DataFrame using the normalized data\n",
    "    df = pd.DataFrame(data_normalized[1:], columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from PIL import Image\n",
    "import base64\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chart dataset that will be used for inference \n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"khhuang/CHOCOLATE\",split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OllamaPullLLM(llm_choice):\n",
    "    if llm_choice == \"gemma\":\n",
    "      ollama.pull('gemma:7b')\n",
    "      model_name = 'gemma:7b'\n",
    "      \n",
    "    elif llm_choice == \"llama\":\n",
    "      ollama.pull('llama2')\n",
    "      model_name = 'llama2'\n",
    "      \n",
    "    elif llm_choice == 'mistral':\n",
    "      ollama.pull('mistral')\n",
    "      model_name = 'mistral'\n",
    "      \n",
    "    elif llm_choice == 'codellama':\n",
    "      ollama.pull('codellama')\n",
    "      model_name = 'codellama'\n",
    "      \n",
    "    elif llm_choice == 'llava':\n",
    "      ollama.pull('llava')\n",
    "      model_name = 'llava'\n",
    "      \n",
    "    else:\n",
    "      ollama.pull('llama2')\n",
    "      model_name = 'llama2'\n",
    "\n",
    "    return model_name\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "    #model = AutoModelForCausalLM.from_pretrained(llm_name)\n",
    "    #return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chart_description(metadata,llm_choice):\n",
    "  tokenizer,model = prepare_llm(llm_choice)\n",
    "\n",
    "  device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "  model.to(device)\n",
    "\n",
    "  prompt = f\"Based on the following chart data: {metadata}, describe the chart's key features and trends.\"\n",
    "\n",
    "  inputs = tokenizer(prompt,return_tensors='pt')\n",
    "  inputs.to(device)\n",
    "  outputs = model.generate(**inputs,max_new_tokens = 200, num_return_sequences=1)\n",
    "  outputs.to(device)\n",
    "  description = tokenizer.decode(outputs[0],skip_special_tokens = True)\n",
    "\n",
    "  return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateChartDescription_Ollama(metadata,image_path,llm_choice):\n",
    "    \n",
    "    llm = OllamaPullLLM(llm_choice)\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))  # Resize to match model input size\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values\n",
    "        \n",
    "    stream = ollama.chat(model = llm, messages =  [{'role': 'user', 'content': f\"You are a part of a chart-to-text deep learning pipeline. The first step of the pipeline involved taking an image of a chart and extracting metadata in tabular format. The next step of the pipeline is for you to Describe what is happening in the following chart image {image}. Use the following extracted chart metadata {metadata} Please describe what is happening in this chart image you explain what is happening in this chart image {image} with the following extracted chart metadata in tabular format as a guide {metadata}?\"}])    \n",
    "    \n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "def PrepareScoringModel():\n",
    "    model_name = 'khhuang/chartve'\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "    processor = DonutProcessor.from_pretrained(model_name)\n",
    "    return model,processor\n",
    "\n",
    "def CaptionAccuracyScoring(model,processor,sentence,image_path):\n",
    "    \n",
    "    def format_query(sentence_string):\n",
    "        return f\"Does the image entail this statement: \\\"{sentence_string}\\\"?\"\n",
    "\n",
    "    # Format text inputs\n",
    "    query = format_query(sentence)\n",
    "\n",
    "    # Encode chart figure and tokenize text\n",
    "    img = Image.open(image_path)\n",
    "    pixel_values = processor(img.convert(\"RGB\"), random_padding=False, return_tensors=\"pt\").pixel_values\n",
    "    decoder_input_ids = processor.tokenizer(query, add_special_tokens=False, return_tensors=\"pt\", max_length=510).input_ids\n",
    "\n",
    "\n",
    "    outputs = model(pixel_values, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "    # Probe the probability of generating \"yes\"\n",
    "    binary_entail_prob_positive = torch.nn.functional.softmax(outputs['logits'].squeeze()[-1,[2334, 49922]])[1].item()\n",
    "\n",
    "    # binary_entail_prob_positive corresponds to the computed probability that the chart entails the caption sentence.\n",
    "    return binary_entail_prob_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreChartDescription(chatstream,image_path,llm_choice,metadata):\n",
    "    description = chatstream['message']['content']\n",
    "    sentence_segmented_descr = description.split('.')\n",
    "    \n",
    "    print(\"Here is the chart description generated by the first pass: \")\n",
    "    print(description)\n",
    "    \n",
    "    print(\"Preparing Scoring Model...\")\n",
    "    model, processor = PrepareScoringModel()\n",
    "    print(\"Finished Preparing Scoring Model\")\n",
    "    \n",
    "    allSentencesAccurateFlag = True\n",
    "    AccuracyStr = {'caption_sentences':[], 'accuracy_score' : []}\n",
    "    for sentence in sentence_segmented_descr:\n",
    "        accuracy_score = CaptionAccuracyScoring(model, processor, sentence,image_path)\n",
    "        AccuracyStr['caption_sentences'].append(sentence)\n",
    "        AccuracyStr['accuracy_score'].append(accuracy_score)\n",
    "        if accuracy_score < 0.93:\n",
    "            allSentencesAccurateFlag = False\n",
    "\n",
    "    print(\"Scored accuracies for caption sentences:\")\n",
    "    print(AccuracyStr)\n",
    "\n",
    "    if not allSentencesAccurateFlag:\n",
    "        # make a generic function for use with ollama.chat that takes as input the prompt we want to use\n",
    "        # we have rewritten a lot of code below\n",
    "        \n",
    "        llm = OllamaPullLLM(llm_choice)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((224, 224))  # Resize to match model input size\n",
    "        image = np.array(image) / 255.0  # Normalize pixel values\n",
    "        \n",
    "        for idx, sentence in enumerate(AccuracyStr['caption_sentences']):\n",
    "            best_scoring_candidate_replacement = sentence\n",
    "            best_score_replacement = AccuracyStr['accuracy_score'][idx]\n",
    "            \n",
    "            sentence_so_far = sentence\n",
    "            i = 0\n",
    "            while (best_score_replacement < 0.93) and (i < 5):\n",
    "                stream = ollama.chat(model = llm, messages = [{'role': 'user', 'content': f\"The following is an image of a chart {image}. Using this chart image and the following extracted chart metadata in tabular format as a guide {metadata}, you generated the following description {description}. This sentence, however, was not very accurate: {sentence}. Generate a single correct sentence to replace the incorrect sentence with a corrected version using the chart image, the metadata, and the description provided to you. Do not preface your answer with a reply simply output the corrected sentence.\"}])\n",
    "                sentence_so_far = stream['message']['content']\n",
    "                i += 1\n",
    "                accuracy_score_sentence_so_far = CaptionAccuracyScoring(model, processor, sentence_so_far,image_path)\n",
    "                if accuracy_score_sentence_so_far > best_score_replacement:\n",
    "                    best_score_replacement = accuracy_score_sentence_so_far\n",
    "                    best_scoring_candidate_replacement = sentence_so_far\n",
    "                    \n",
    "            AccuracyStr['caption_sentences'][idx] = best_scoring_candidate_replacement\n",
    "            AccuracyStr['accuracy_score'][idx] = best_score_replacement\n",
    "            \n",
    "    return AccuracyStr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ni=1\\n\\nfor sample in dataset:\\n  image_path = sample['image_path']  # Adjust this key based on the actual dataset structure\\n  save_path = 'TheBoard/ChartImages/Chart_Example_'+str(i)+'.png'\\n  i+=1\\n  torch.hub.download_url_to_file(image_path, save_path)\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "i=1\n",
    "\n",
    "for sample in dataset:\n",
    "  image_path = sample['image_path']  # Adjust this key based on the actual dataset structure\n",
    "  save_path = 'TheBoard/ChartImages/Chart_Example_'+str(i)+'.png'\n",
    "  i+=1\n",
    "  torch.hub.download_url_to_file(image_path, save_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'TheBoard/ChartImages/Chart_Example_8.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it took 10 minutes almost to load deplot model weights but under a minute to make the prediction\n",
    "metadata = ExtractChartMetadata(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TITLE | Number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, by region<0x0A>region | Number of hate crimes*<0x0A>in England | Wales from April 2019 to March 2020<0x0A>in England and Wales from April 2019 to March 2020<0x0A>2020 | <0x0A> West Midlands | 9.4 | 8.1 | 8.1 | 7.6 <0x0A> Yorkshire and the Humber | 9.4 | 7.8 | 4.8 | 4.6 <0x0A> South West | 10.5 | 10.5 | 5.4 | 10.5 <0x0A> North West | 5.4 | 7.2 | 3.1 | 3.1 <0x0A> London | 17.6 | 17.7 | 17.5 | 17.5 <0x0A> East Midlands | 4.8 | 4.6 | 4.6 | 4.8'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stream = GenerateChartDescription_Ollama(metadata = metadata,image_path = image_path,llm_choice = 'llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama2',\n",
       " 'created_at': '2024-03-21T00:10:30.173456Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'The chart image you provided shows the number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, broken down by region. The metadata extracted from the chart is as follows:\\n\\nTITLE | Number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, by region\\n\\nregion | Number of hate crimes*\\n\\nin England | Wales from April 2019 to March 2020\\n\\nin England and Wales from April 2019 to March 2020\\n\\n2020 |\\n\\nWest Midlands | 9.4 | 8.1 | 8.1 | 7.6\\n\\nYorkshire and the Humber | 9.4 | 7.8 | 4.8 | 4.6\\n\\nSouth West | 10.5 | 10.5 | 5.4 | 10.5\\n\\nNorth West | 5.4 | 7.2 | 3.1 | 3.1\\n\\nLondon | 17.6 | 17.7 | 17.5 | 17.5\\n\\nEast Midlands | 4.8 | 4.6 | 4.6 | 4.8\\n\\n*Note: The numbers are represented as bars in the chart, with the height of each bar indicating the number of hate crimes in that region.'},\n",
       " 'done': True,\n",
       " 'total_duration': 11742212500,\n",
       " 'load_duration': 498834166,\n",
       " 'prompt_eval_count': 1663,\n",
       " 'prompt_eval_duration': 3074989000,\n",
       " 'eval_count': 337,\n",
       " 'eval_duration': 8166581000}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the chart description generated by the first pass: \n",
      "The chart image you provided shows the number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, broken down by region. The metadata extracted from the chart is as follows:\n",
      "\n",
      "TITLE | Number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, by region\n",
      "\n",
      "region | Number of hate crimes*\n",
      "\n",
      "in England | Wales from April 2019 to March 2020\n",
      "\n",
      "in England and Wales from April 2019 to March 2020\n",
      "\n",
      "2020 |\n",
      "\n",
      "West Midlands | 9.4 | 8.1 | 8.1 | 7.6\n",
      "\n",
      "Yorkshire and the Humber | 9.4 | 7.8 | 4.8 | 4.6\n",
      "\n",
      "South West | 10.5 | 10.5 | 5.4 | 10.5\n",
      "\n",
      "North West | 5.4 | 7.2 | 3.1 | 3.1\n",
      "\n",
      "London | 17.6 | 17.7 | 17.5 | 17.5\n",
      "\n",
      "East Midlands | 4.8 | 4.6 | 4.6 | 4.8\n",
      "\n",
      "*Note: The numbers are represented as bars in the chart, with the height of each bar indicating the number of hate crimes in that region.\n",
      "Preparing Scoring Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Preparing Scoring Model\n",
      "Scored accuracies for caption sentences:\n",
      "{'caption_sentences': ['The chart image you provided shows the number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, broken down by region', ' The metadata extracted from the chart is as follows:\\n\\nTITLE | Number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, by region\\n\\nregion | Number of hate crimes*\\n\\nin England | Wales from April 2019 to March 2020\\n\\nin England and Wales from April 2019 to March 2020\\n\\n2020 |\\n\\nWest Midlands | 9', '4 | 8', '1 | 8', '1 | 7', '6\\n\\nYorkshire and the Humber | 9', '4 | 7', '8 | 4', '8 | 4', '6\\n\\nSouth West | 10', '5 | 10', '5 | 5', '4 | 10', '5\\n\\nNorth West | 5', '4 | 7', '2 | 3', '1 | 3', '1\\n\\nLondon | 17', '6 | 17', '7 | 17', '5 | 17', '5\\n\\nEast Midlands | 4', '8 | 4', '6 | 4', '6 | 4', '8\\n\\n*Note: The numbers are represented as bars in the chart, with the height of each bar indicating the number of hate crimes in that region', ''], 'accuracy_score': [0.9511191844940186, 0.0762731283903122, 0.07475849986076355, 0.1085427924990654, 0.06143795698881149, 0.2753892242908478, 0.0655503123998642, 0.07246902585029602, 0.07246902585029602, 0.245934396982193, 0.13047680258750916, 0.12981124222278595, 0.09643322229385376, 0.43456482887268066, 0.0655503123998642, 0.12301722913980484, 0.11496568471193314, 0.0024022541474550962, 0.0028358232229948044, 0.0029714053962379694, 0.004747200291603804, 0.1649211347103119, 0.07246902585029602, 0.13420887291431427, 0.13420887291431427, 0.7801610827445984, 0.07581326365470886]}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "AccuracyStr = ScoreChartDescription(chatstream = stream,image_path = image_path,llm_choice = 'llama',metadata = metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caption_sentences': ['The chart image you provided shows the number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, broken down by region',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in the West Midlands region, with 9.4 incidents in total, followed by the Yorkshire and the Humber region with 9.4 incidents.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes reported in that region alone.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in the West Midlands with 9.4 incidents, followed by Yorkshire and the Humber with 9.4 incidents.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes in that region alone.',\n",
       "  'The number of racially motivated hate crimes in Yorkshire and the Humber was 9.4 in April 2019-March 2020.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands region was 9.4 in April 2019-March 2020, with 8.1 in Wales and 8.1 in England and Wales during the same period.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands region was 9.4, 8.1, and 8.1 in April 2019 to March 2020, respectively, and 7.6 in 2020.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands was 9.4 in April 2019 to March 2020, 8.1 in Wales, and 8.1 in both England and Wales from April 2019 to March 2020.',\n",
       "  'The number of racially motivated hate crimes in the South West region was 10.5 in England and Wales from April 2019 to March 2020, according to the chart image and metadata provided.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes in that region.',\n",
       "  '5 | 5',\n",
       "  'The number of racially motivated hate crimes in the West Midlands region was 9.4, 8.1, and 8.1 in April 2019 to March 2020, respectively, and 7.6 in 2020.',\n",
       "  '5\\n\\nNorth West | 5',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes in that region.',\n",
       "  '2 | 3',\n",
       "  '1 | 3',\n",
       "  'The corrected sentence is:\\nLondon had the highest number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, with 17.6 hate crimes in that region.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes reported in that region alone.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020, by region, was:\\n\\nIn England and Wales, there were 17.6 hate crimes in 2020.',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in London, with 17.6 hate crimes in 2020 alone.',\n",
       "  'The corrected sentence is:\\nThe East Midlands region experienced 4.2 hate crimes in England and Wales from April 2019 to March 2020, according to the chart image and metadata provided.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands was 9.4, 8.1, and 8.1 in April 2019 to March 2020, respectively, and 7.6 in 2020.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands region was 9.4 in April 2019 and March 2020, with a total of 8.1 hate crimes in England and Wales from April 2019 to March 2020.',\n",
       "  'The number of racially motivated hate crimes in the West Midlands region was 9.4, 8.1, and 8.1 from April 2019 to March 2020, respectively, with a total of 7.6 hate crimes in England and Wales during the same period.',\n",
       "  '8\\n\\n*Note: The numbers are represented as bars in the chart, with the height of each bar indicating the number of hate crimes in that region',\n",
       "  'The number of racially motivated hate crimes in England and Wales from April 2019 to March 2020 was highest in the West Midlands with 9.4 incidents, followed by Yorkshire and the Humber with 9.4 incidents, South West with 10.5 incidents, North West with 5.4 incidents, London with 17.6 incidents, and East Midlands with 4.8 incidents.'],\n",
       " 'accuracy_score': [0.9511191844940186,\n",
       "  0.16574864089488983,\n",
       "  0.31520628929138184,\n",
       "  0.14915531873703003,\n",
       "  0.31203991174697876,\n",
       "  0.4909658432006836,\n",
       "  0.2682197690010071,\n",
       "  0.3038141131401062,\n",
       "  0.2832234799861908,\n",
       "  0.28746533393859863,\n",
       "  0.28015995025634766,\n",
       "  0.12981124222278595,\n",
       "  0.3038141131401062,\n",
       "  0.43456482887268066,\n",
       "  0.28015995025634766,\n",
       "  0.12301722913980484,\n",
       "  0.11496568471193314,\n",
       "  0.43814557790756226,\n",
       "  0.31520628929138184,\n",
       "  0.49072369933128357,\n",
       "  0.3139543831348419,\n",
       "  0.21652814745903015,\n",
       "  0.3008803725242615,\n",
       "  0.22039684653282166,\n",
       "  0.332027792930603,\n",
       "  0.7801610827445984,\n",
       "  0.07668758183717728]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AccuracyStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'TheBoard/ChartImages/Chart_Example_9.png'\n",
    "image = Image.open(image_path)\n",
    "image = image.resize((224, 224))  # Resize to match model input size\n",
    "image = np.array(image) / 255.0  # Normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TITLE | Number of social network users worldwide in 2020, by region (in millions)<0x0A>geographic region | Number of active social media users in millions <0x0A> Western Asia | 164.82 <0x0A> Western Africa | 38.22 <0x0A> Southern Europe | 151.22 <0x0A> Southern Africa | 17.15 <0x0A> Southeast Asia | 479.15 <0x0A> South America | 260.0 <0x0A> Northern America | 326.93 <0x0A> Northern Africa | 106.51 <0x0A> Eastern Asia | 102.97 <0x0A> Eastern Africa | 30.53 <0x0A> Central Asia | 10.92 <0x0A> Central Africa | 11.17 <0x0A> Caribbean | 10.35 <0x0A> Australia & Oceania | 10.3'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamLLAMA = ollama.chat(model = 'llama2', messages =  [{'role': 'user', 'content': f\"You are a part of a chart-to-text deep learning pipeline. The first step of the pipeline involved taking an image of a chart and extracting metadata in tabular format. The next step of the pipeline is for you to take the extracted metadata and the image of the chart and use this supplied information to describe what is happening in the chart image. I want you to pay special attention to the title, any legends, x-axis, and y-axis labels, and what the data points represent. Here is the metadata: {metadata}. Here is the image: {image}.\"}])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamLLAVA = ollama.chat(model = 'llava', messages =  [{'role': 'user', 'content': f\"You are a part of a chart-to-text deep learning pipeline. The first step of the pipeline involved taking an image of a chart and extracting metadata in tabular format. The next step of the pipeline is for you to take the extracted metadata and the image of the chart and use this supplied information to describe what is happening in the chart image. I want you to pay special attention to the title, any legends, x-axis, and y-axis labels, and what the data points represent. Here is the metadata: {metadata}. Here is the image: {image}.\"}])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama2',\n",
       " 'created_at': '2024-03-17T19:07:27.086878Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'Based on the provided image and metadata, I can identify the following:\\n\\nTitle: The chart shows the number of social network users worldwide in 2020, broken down by region.\\n\\nGeographic Region: The chart provides the number of active social media users in millions for each of the following regions:\\n\\n* Western Asia: 164.82 million\\n* Western Africa: 38.22 million\\n* Southern Europe: 151.22 million\\n* Southern Africa: 17.15 million\\n* Southeast Asia: 479.15 million\\n* South America: 260.0 million\\n* Northern America: 326.93 million\\n* Northern Africa: 106.51 million\\n* Eastern Asia: 102.97 million\\n* Eastern Africa: 30.53 million\\n* Central Asia: 10.92 million\\n* Central Africa: 11.17 million\\n* Caribbean: 10.35 million\\n* Australia & Oceania: 10.3 million\\n\\nThe chart shows a total of 1,486.73 million active social media users worldwide in 2020, with the majority residing in Southeast Asia and Southern Africa.'},\n",
       " 'done': True,\n",
       " 'total_duration': 7336345666,\n",
       " 'load_duration': 1676166,\n",
       " 'prompt_eval_duration': 157519000,\n",
       " 'eval_count': 293,\n",
       " 'eval_duration': 7174330000}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llava',\n",
       " 'created_at': '2024-03-17T19:07:32.824896Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': ' The image you have provided appears to be a blank page with no content visible. Please check the URL or file path of the image and ensure that it is correct before providing it again for further processing in the chart-to-text pipeline. If you continue to experience issues, please let me know so I can assist you further. '},\n",
       " 'done': True,\n",
       " 'total_duration': 5693369333,\n",
       " 'load_duration': 635018666,\n",
       " 'prompt_eval_count': 1788,\n",
       " 'prompt_eval_duration': 3466112000,\n",
       " 'eval_count': 68,\n",
       " 'eval_duration': 1590360000}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamLLAVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd74d972f4a4a08a5d1cc52a51435d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
